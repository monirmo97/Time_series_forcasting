{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGLclyVfTRom"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main():\n",
        "    # Check if GPU is available\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load data\n",
        "    data = pd.read_csv('/content/drive/MyDrive/ETTh1.csv')\n",
        "\n",
        "    # Preprocess the data\n",
        "    data['date'] = pd.to_datetime(data['date'])\n",
        "    data.set_index('date', inplace=True)\n",
        "\n",
        "    features = data[['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL']].values\n",
        "    target = data['OT'].values.reshape(-1, 1)\n",
        "\n",
        "    scaler_features = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_features = scaler_features.fit_transform(features)\n",
        "\n",
        "    scaler_target = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_target = scaler_target.fit_transform(target)\n",
        "\n",
        "    # Create sequences\n",
        "    def create_sequences(data, target, seq_length):\n",
        "        xs, ys = [], []\n",
        "        for i in range(len(data) - seq_length):\n",
        "            x = data[i:(i + seq_length)]\n",
        "            y = target[i + seq_length]\n",
        "            xs.append(x)\n",
        "            ys.append(y)\n",
        "        return np.array(xs), np.array(ys)\n",
        "\n",
        "    seq_length = 48 # Adjusted sequence length for more context\n",
        "    X, y = create_sequences(scaled_features, scaled_target, seq_length)\n",
        "\n",
        "    # Split the data\n",
        "    train_ratio, val_ratio, test_ratio = 0.6, 0.2, 0.2\n",
        "    total_size = len(X)\n",
        "    train_size = int(total_size * train_ratio)\n",
        "    val_size = int(total_size * val_ratio)\n",
        "    test_size = total_size - train_size - val_size\n",
        "\n",
        "    X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[-test_size:]\n",
        "    y_train, y_val, y_test = y[:train_size], y[train_size:train_size + val_size], y[-test_size:]\n",
        "\n",
        "    # Convert data to PyTorch tensors\n",
        "    X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)\n",
        "    X_val, y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32)\n",
        "    X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    val_dataset = TensorDataset(X_val, y_val)\n",
        "    test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # Adjusted batch size\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Define the GRU model\n",
        "    class GRUModel(nn.Module):\n",
        "        def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
        "            super(GRUModel, self).__init__()\n",
        "            self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=0.3)\n",
        "            self.fc1 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
        "            self.fc2 = nn.Linear(hidden_dim // 2, output_dim)\n",
        "            self.relu = nn.ReLU()\n",
        "            self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        def forward(self, x):\n",
        "            h0 = torch.zeros(2, x.size(0), 50).to(device)\n",
        "            out, _ = self.gru(x, h0)\n",
        "            out = self.fc1(out[:, -1, :])\n",
        "            out = self.relu(out)\n",
        "            out = self.dropout(out)\n",
        "            out = self.fc2(out)\n",
        "            return out\n",
        "\n",
        "    model = GRUModel(input_dim=6, hidden_dim=50, output_dim=1, num_layers=2).to(device)\n",
        "\n",
        "    criterion = nn.MSELoss()  # Mean Squared Error (MSE)\n",
        "    # criterion = nn.L1Loss()  # Mean Absolute Error (MAE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)  # Adjusted learning rate\n",
        "\n",
        "    # Train the model\n",
        "    best_loss = float('inf')\n",
        "    for epoch in range(100):  # Increased number of epochs\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        val_losses = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                outputs = model(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "                val_losses.append(loss.item())\n",
        "\n",
        "        train_loss = np.mean(train_losses)\n",
        "        val_loss = np.mean(val_losses)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "    model.eval()\n",
        "\n",
        "    y_preds = []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, _ in test_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            y_preds.append(outputs.cpu().numpy())\n",
        "\n",
        "    y_pred = np.concatenate(y_preds, axis=0)\n",
        "    y_test = y_test.numpy()\n",
        "\n",
        "    # Inverse transform the predictions and test data\n",
        "    # y_pred = scaler_target.inverse_transform(y_pred)\n",
        "    # y_test = scaler_target.inverse_transform(y_test)\n",
        "\n",
        "    # Calculate MAE and R2 score\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f'Test MAE: {mae:.4f}')\n",
        "    print(f'R2 Score: {r2:.4f}')\n",
        "\n",
        "    # Plot predictions\n",
        "    start_index = 0\n",
        "    end_index = 100\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(y_test[start_index:end_index], label='True Value', linestyle='dotted')\n",
        "    plt.plot(y_pred[start_index:end_index], label='Predicted Value', linestyle='dotted')\n",
        "    plt.title('Oil Temperature Prediction')\n",
        "    plt.xlabel('Time Step')\n",
        "    plt.ylabel('Oil Temperature')\n",
        "    plt.legend()\n",
        "    plt.savefig('predictions_plot_GRU.png')  # Save the plot\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}